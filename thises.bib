@inproceedings{touvron2019fixing,
  title={Fixing the train-test resolution discrepancy},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8252--8262},
  year={2019}
}

@article{hoffer2019mix,
  title={Mix \& Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency},
  author={Hoffer, Elad and Weinstein, Berry and Hubara, Itay and Ben-Nun, Tal and Hoefler, Torsten and Soudry, Daniel},
  journal={arXiv preprint arXiv:1908.08986},
  year={2019}
}

@article{DBLP:journals/corr/KanazawaSJ14,
  author    = {Angjoo Kanazawa and
               Abhishek Sharma and
               David W. Jacobs},
  title     = {Locally Scale-Invariant Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1412.5104},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.5104},
  archivePrefix = {arXiv},
  eprint    = {1412.5104},
  timestamp = {Tue, 24 Sep 2019 16:41:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KanazawaSJ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ragan2013halide,
  title={Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines},
  author={Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr{\'e}do and Amarasinghe, Saman},
  journal={Acm Sigplan Notices},
  volume={48},
  number={6},
  pages={519--530},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@inproceedings {chen2018tvm,
author = {Tianqi Chen and Thierry Moreau and Ziheng Jiang and Lianmin Zheng and Eddie Yan and Haichen Shen and Meghan Cowan and Leyuan Wang and Yuwei Hu and Luis Ceze and Carlos Guestrin and Arvind Krishnamurthy},
title = {{TVM}: An Automated End-to-End Optimizing Compiler for Deep Learning},
booktitle = {13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
year = {2018},
isbn = {978-1-939133-08-3},
address = {Carlsbad, CA},
pages = {578--594},
url = {https://www.usenix.org/conference/osdi18/presentation/chen},
publisher = {{USENIX} Association},
month = oct,
}

@inproceedings{shen2017fast,
  title={Fast video classification via adaptive cascading of deep models},
  author={Shen, Haichen and Han, Seungyeop and Philipose, Matthai and Krishnamurthy, Arvind},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3646--3654},
  year={2017}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

@article{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}

@article{guo2016high,
  title={High-density image storage using approximate memory cells},
  author={Guo, Qing and Strauss, Karin and Ceze, Luis and Malvar, Henrique S},
  journal={ACM SIGPLAN Notices},
  volume={51},
  number={4},
  pages={413--426},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@article{lepikhin2020gshard,
  title={Gshard: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}

@article{yang2019soft,
  title={Soft conditional computation},
  author={Yang, Brandon and Bender, Gabriel and Le, Quoc V and Ngiam, Jiquan},
  journal={arXiv preprint arXiv:1904.04971},
  volume={3},
  number={4},
  pages={5},
  year={2019}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={554--561},
  year={2013}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@article{sampson2014approximate,
  title={Approximate storage in solid-state memories},
  author={Sampson, Adrian and Nelson, Jacob and Strauss, Karin and Ceze, Luis},
  journal={ACM Transactions on Computer Systems (TOCS)},
  volume={32},
  number={3},
  pages={1--23},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@inproceedings{rastegari2016xnor,
  title={Xnor-net: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European conference on computer vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}

@article{zhou2016dorefa,
  title={Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients},
  author={Zhou, Shuchang and Wu, Yuxin and Ni, Zekun and Zhou, Xinyu and Wen, He and Zou, Yuheng},
  journal={arXiv preprint arXiv:1606.06160},
  year={2016}
}

@article{fromm2020riptide,
  title={Riptide: Fast end-to-end binarized neural networks},
  author={Fromm, Joshua and Cowan, Meghan and Philipose, Matthai and Ceze, Luis and Patel, Shwetak},
  journal={Proceedings of Machine Learning and Systems 2020},
  volume={2},
  year={2020}
}

@article{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:1803.03635},
  year={2018}
}

@inproceedings{ji2018tetris,
  title={Tetris: Tile-matching the tremendous irregular sparsity},
  author={Ji, Yu and Liang, Ling and Deng, Lei and Zhang, Youyang and Zhang, Youhui and Xie, Yuan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4115--4125},
  year={2018}
}

@article{yang2018energy,
  title={Energy-constrained compression for deep neural networks via weighted sparse projection and layer input masking},
  author={Yang, Haichuan and Zhu, Yuhao and Liu, Ji},
  journal={arXiv preprint arXiv:1806.04321},
  year={2018}
}

@inproceedings{buckler2018eva2,
  title={EVA$^2$: Exploiting Temporal Redundancy in Live Computer Vision},
  author={Buckler, Mark and Bedoukian, Philip and Jayasuriya, Suren and Sampson, Adrian},
  booktitle={2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)},
  pages={533--546},
  year={2018},
  organization={IEEE}
}

@inproceedings{kim2016dynamic,
  title={Dynamic energy-accuracy trade-off using stochastic computing in deep neural networks},
  author={Kim, Kyounghoon and Kim, Jungki and Yu, Joonsang and Seo, Jungwoo and Lee, Jongeun and Choi, Kiyoung},
  booktitle={Proceedings of the 53rd Annual Design Automation Conference},
  pages={1--6},
  year={2016}
}

@inproceedings{lee2017energy,
  title={Energy-efficient hybrid stochastic-binary neural networks for near-sensor computing},
  author={Lee, Vincent T and Alaghi, Armin and Hayes, John P and Sathe, Visvesh and Ceze, Luis},
  booktitle={Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2017},
  pages={13--18},
  year={2017},
  organization={IEEE}
}

@article{kalamkar2019study,
  title={A study of bfloat16 for deep learning training},
  author={Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi, Naveen and Das, Dipankar and Banerjee, Kunal and Avancha, Sasikanth and Vooturi, Dharma Teja and Jammalamadaka, Nataraj and Huang, Jianyu and Yuen, Hector and others},
  journal={arXiv preprint arXiv:1905.12322},
  year={2019}
}

@article{zheng2020ansor,
  title={Ansor: Generating High-Performance Tensor Programs for Deep Learning},
  author={Zheng, Lianmin and Jia, Chengfan and Sun, Minmin and Wu, Zhao and Yu, Cody Hao and Haj-Ali, Ameer and Wang, Yida and Yang, Jun and Zhuo, Danyang and Sen, Koushik and others},
  journal={arXiv preprint arXiv:2006.06762},
  year={2020}
}

@inproceedings{cowan2020automatic,
  title={Automatic generation of high-performance quantized machine learning kernels},
  author={Cowan, Meghan and Moreau, Thierry and Chen, Tianqi and Bornholt, James and Ceze, Luis},
  booktitle={Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
  pages={305--316},
  year={2020}
}

@inproceedings{jevdjic2017approximate,
  title={Approximate storage of compressed and encrypted videos},
  author={Jevdjic, Djordje and Strauss, Karin and Ceze, Luis and Malvar, Henrique S},
  booktitle={Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={361--373},
  year={2017}
}

@article{mazumdar2019vignette,
  title={Vignette: Perceptual Compression for Video Storage and Processing Systems},
  author={Mazumdar, Amrita and Haynes, Brandon and Balazinska, Magdalena and Ceze, Luis and Cheung, Alvin and Oskin, Mark},
  journal={arXiv preprint arXiv:1902.01372},
  year={2019}
}

@article{wang2011reduced,
  title={Reduced-and no-reference image quality assessment},
  author={Wang, Zhou and Bovik, Alan C},
  journal={IEEE Signal Processing Magazine},
  volume={28},
  number={6},
  pages={29--40},
  year={2011},
  publisher={IEEE}
}

@inproceedings{chen2018learning,
  title={Learning to optimize tensor programs},
  author={Chen, Tianqi and Zheng, Lianmin and Yan, Eddie and Jiang, Ziheng and Moreau, Thierry and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3389--3400},
  year={2018}
}

@inproceedings{zhou2016learning,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}

@inproceedings{yan2017customizing,
  title={Customizing Progressive {JPEG} for Efficient Image Storage},
  author={Yan, Eddie and Zhang, Kaiyuan and Wang, Xi and Strauss, Karin and Ceze, Luis},
  booktitle={9th {USENIX} Workshop on Hot Topics in Storage and File Systems (HotStorage 17)},
  year={2017}
}

@inproceedings{beaver2010finding,
  title={Finding a Needle in {Haystack}: {Facebook}'s Photo Storage},
  author={Beaver, Doug and Kumar, Sanjeev and Li, Harry C and Sobel, Jason and
        Vajgel, Peter and others},
  booktitle={OSDI},
  volume={10},
  pages={1--8},
  year={2010}
}

@inproceedings{tang2015ripq,
  title={{RIPQ}: Advanced Photo Caching on Flash for {Facebook}},
  author={Tang, Linpeng and Huang, Qi and Lloyd, Wyatt and Kumar, Sanjeev and
Li, Kai},
  booktitle={13th USENIX Conference on File and Storage Technologies (FAST 15)},
  pages={373--386},
  year={2015}
}

@inproceedings{carillon,
  title = {Enabling Space Elasticity in Storage Systems},
  author = {Helgi Sigurbjarnarson and Petur O. Ragnarsson and Juncheng Yang and Ymir Vigfusson and Mahesh Balakrishnan},
  year = 2016,
  booktitle = {9th ACM International on Systems and Storage Conference~(SYSTOR)},
  address = {Haifa, Israel},
}

@misc{zimg,
    title={zimg - A lightweight and high performance image storage and processing system},
    howpublished={\url{http://zimg.buaa.us/}}
}

@misc{flickr,
    title={A Year Without a Byte},
    howpublished={\url{https://code.flickr.net/2017/01/05/a-year-without-a-byte/}}
}

@misc{fasterfacebook,
    title={Faster Photos in {Facebook} for {iOS}},
    howpublished={\url{https://code.facebook.com/posts/857662304298232/faster-photos-in-facebook-for-ios/}},
    author={Bar, Tomer}
}

@inproceedings{huang2013analysis,
  title={An analysis of {Facebook} photo caching},
  author={Huang, Qi and Birman, Ken and van Renesse, Robbert and Lloyd, Wyatt and Kumar, Sanjeev and Li, Harry C},
  booktitle={Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
  pages={167--181},
  year={2013},
  organization={ACM}
}

@inproceedings {183605,
	author = {Helgi Sigurbjarnarson and Petur Orri Ragnarsson and Ymir Vigfusson and Mahesh Balakrishnan},
	title = {Harmonium: Elastic Cloud Storage via File Motifs},
	booktitle = {6th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage 14)},
	year = {2014},
	address = {Philadelphia, PA},
	url = {https://www.usenix.org/conference/hotstorage14/workshop-program/presentation/sigurbjarnarson},
	publisher = {USENIX Association},
}

@inproceedings{huiskes08,
 author = {Mark J. Huiskes and Michael S. Lew},
 title = {The {MIR Flickr} Retrieval Evaluation},
 booktitle = {MIR '08: Proceedings of the 2008 ACM International Conference on Multimedia Information Retrieval},
 year = {2008},
 location = {Vancouver, Canada},
 publisher = {ACM},
 address = {New York, NY, USA},
}



@misc{computation,
    title={{JPEG} image compression FAQ, part 1/2},
    author={Lane, Tom},
    howpublished={\url{http://www.faqs.org/faqs/jpeg-faq/part1/index.html}}
}

@book{souders2009even,
  title={Even faster web sites: performance best practices for web developers},
  author={Souders, Steve},
  year={2009},
  publisher={O'Reilly Media, Inc.}
}

@article{wallace1992jpeg,
  title={The {JPEG} still picture compression standard},
  author={Wallace, Gregory K},
  journal={IEEE transactions on consumer electronics},
  volume={38},
  number={1},
  pages={xviii--xxxiv},
  year={1992},
  publisher={IEEE}
}

@misc{independent2014libjpeg,
  title={Libjpeg},
  author={{Independent JPEG Group and others}},
  journal={2010-07-10]. http://www. ijg. org},
  year={2014}
}

@inproceedings{gupta-mascots14,
  title={An Economic Perspective of Disk vs. Flash Media in Archival Storage},
  author={Preeti Gupta and Avani Wildani† and Ethan L. Miller and Daniel Rosenthal and Ian F. Adams and Christina Strong and Andy Hospodor},
  booktitle={IEEE MASCOTS},
  year={2014}
 }

@inproceedings{black2016feeding,
  title={Feeding the Pelican: using archival hard drives for cold storage
racks},
  author={Black, Richard and Donnelly, Austin and Harper, Dave and Ogus, Aaron
and Rowstron, Anthony},
  booktitle={8th USENIX Workshop on Hot Topics in Storage and File Systems
(HotStorage 16)},
  year={2016},
  organization={USENIX Association}
}

@misc{imagemagick2008imagemagick,
  title={ImageMagick},
  author={{ImageMagick Studio, LLC}},
  year={2008}
}

@inproceedings{wang2002no,
  title={No-reference perceptual quality assessment of {JPEG} compressed images},
  author={Wang, Zhou and Sheikh, Hamid R and Bovik, Alan C},
  booktitle={IEEE International Conference on Image Processing},
  volume={1},
  year={2002},
  organization={IEEE}
}

@InProceedings{pmlr-v97-zhang19a,
  title =    {Making Convolutional Networks Shift-Invariant Again},
  author =   {Zhang, Richard},
  booktitle =    {Proceedings of the 36th International Conference on Machine Learning},
  pages =    {7324--7334},
  year =     {2019},
  editor =   {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume =   {97},
  series =   {Proceedings of Machine Learning Research},
  address =      {Long Beach, California, USA},
  month =    {09--15 Jun},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v97/zhang19a/zhang19a.pdf},
  url =      {http://proceedings.mlr.press/v97/zhang19a.html},
  abstract =     {Modern convolutional networks are not shift-invariant, as small input shifts or translations can cause drastic changes in the output. Commonly used downsampling methods, such as max-pooling, strided-convolution, and average-pooling, ignore the sampling theorem. The well-known signal processing fix is anti-aliasing by low-pass filtering before downsampling. However, simply inserting this module into deep networks leads to performance degradation; as a result, it is seldomly used today. We show that when integrated correctly, it is compatible with existing architectural components, such as max-pooling. The technique is general and can be incorporated across layer types and applications, such as image classification and conditional image generation. In addition to increased shift-invariance, we also observe, surprisingly, that anti-aliasing boosts accuracy in ImageNet classification, across several commonly-used architectures. This indicates that anti-aliasing serves as effective regularization. Our results demonstrate that this classical signal processing technique has been undeservingly overlooked in modern deep networks.}
}

@ARTICLE{2019arXiv191104252X,
       author = {{Xie}, Qizhe and {Luong}, Minh-Thang and {Hovy}, Eduard and
         {Le}, Quoc V.},
        title = "{Self-training with Noisy Student improves ImageNet classification}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2019",
        month = "Nov",
          eid = {arXiv:1911.04252},
        pages = {arXiv:1911.04252},
archivePrefix = {arXiv},
       eprint = {1911.04252},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191104252X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@incollection{NIPS2019_9035,
title = {Fixing the train-test resolution discrepancy},
author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8250--8260},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9035-fixing-the-train-test-resolution-discrepancy.pdf}
}

@InProceedings{pmlr-v97-tan19a,
  title =    {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author =   {Tan, Mingxing and Le, Quoc},
  booktitle =    {Proceedings of the 36th International Conference on Machine Learning},
  pages =    {6105--6114},
  year =     {2019},
  editor =   {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume =   {97},
  series =   {Proceedings of Machine Learning Research},
  address =      {Long Beach, California, USA},
  month =    {09--15 Jun},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url =      {http://proceedings.mlr.press/v97/tan19a.html},
  abstract =     {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the aaai conference on artificial intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}

@inproceedings{gueguen2018faster,
  title={Faster neural networks straight from jpeg},
  author={Gueguen, Lionel and Sergeev, Alex and Kadlec, Ben and Liu, Rosanne and Yosinski, Jason},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3933--3944},
  year={2018}
}

@InProceedings{Zhou_2016_CVPR,
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
title = {Learning Deep Features for Discriminative Localization},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@inproceedings{islam2019much,
  title={How much Position Information Do Convolutional Neural Networks Encode?},
  author={Islam, Md Amirul and Jia, Sen and Bruce, Neil DB},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@incollection{NIPS2019_8412,
title = {CondConv: Conditionally Parameterized Convolutions for Efficient Inference},
author = {Yang, Brandon and Bender, Gabriel and Le, Quoc V and Ngiam, Jiquan},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {1305--1316},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8412-condconv-conditionally-parameterized-convolutions-for-efficient-inference.pdf}
}

@inproceedings{chen2009ranking,
  title={Ranking measures and loss functions in learning to rank},
  author={Chen, Wei and Liu, Tie-Yan and Lan, Yanyan and Ma, Zhi-Ming and Li, Hang},
  booktitle={Advances in Neural Information Processing Systems},
  pages={315--323},
  year={2009}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={6023--6032},
  year={2019}
}

@inproceedings{ciregan2012multi,
  title={Multi-column deep neural networks for image classification},
  author={Ciregan, Dan and Meier, Ueli and Schmidhuber, J{\"u}rgen},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={3642--3649},
  year={2012},
  organization={IEEE}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}
@article{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1611.01578},
  year={2016}
}

@inproceedings{cubuk2019autoaugment,
  title={Autoaugment: Learning augmentation strategies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={113--123},
  year={2019}
}

@article{xie2019adversarial,
  title={Adversarial Examples Improve Image Recognition},
  author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan and Le, Quoc V},
  journal={arXiv preprint arXiv:1911.09665},
  year={2019}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@article{pereira2009machine,
  title={Machine learning classifiers and fMRI: a tutorial overview},
  author={Pereira, Francisco and Mitchell, Tom and Botvinick, Matthew},
  journal={Neuroimage},
  volume={45},
  number={1},
  pages={S199--S209},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{berthelot2019mixmatch,
  title={Mixmatch: A holistic approach to semi-supervised learning},
  author={Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5050--5060},
  year={2019}
}

@article{devries2017improved,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

@InProceedings{Nguyen_2015_CVPR,
author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
title = {Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{wong2016understanding,
  title={Understanding data augmentation for classification: when to warp?},
  author={Wong, Sebastien C and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D},
  booktitle={2016 international conference on digital image computing: techniques and applications (DICTA)},
  pages={1--6},
  year={2016},
  organization={IEEE}
}

@inproceedings{lin2016visualizing,
  title={Visualizing and understanding deep texture representations},
  author={Lin, Tsung-Yu and Maji, Subhransu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2791--2799},
  year={2016}
}

@inproceedings{gatys2015texture,
  title={Texture synthesis using convolutional neural networks},
  author={Gatys, Leon and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Advances in neural information processing systems},
  pages={262--270},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@misc{alex2020radioactive,
    title={Radioactive data: tracing through training},
    author={Alexandre Sablayrolles and Matthijs Douze and Cordelia Schmid and Hervé Jégou},
    year={2020},
    eprint={2002.00937},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{erhan2009visualizing,
  title={Visualizing higher-layer features of a deep network},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  year={2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@inproceedings{cohen2016group,
  title={Group equivariant convolutional networks},
  author={Cohen, Taco and Welling, Max},
  booktitle={International conference on machine learning},
  pages={2990--2999},
  year={2016}
}

@article{sosnovik2019scale,
  title={Scale-equivariant steerable networks},
  author={Sosnovik, Ivan and Szmaja, Micha{\l} and Smeulders, Arnold},
  journal={arXiv preprint arXiv:1910.11093},
  year={2019}
}

@article{zhu2019scale,
  title={Scale-Equivariant Neural Networks with Decomposed Convolutional Filters},
  author={Zhu, Wei and Qiu, Qiang and Calderbank, Robert and Sapiro, Guillermo and Cheng, Xiuyuan},
  journal={arXiv preprint arXiv:1909.11193},
  year={2019}
}

@article{kondor2018generalization,
  title={On the generalization of equivariance and convolution in neural networks to the action of compact groups},
  author={Kondor, Risi and Trivedi, Shubhendu},
  journal={arXiv preprint arXiv:1802.03690},
  year={2018}
}

@article{dao2019kernel,
  title={A kernel theory of modern data augmentation},
  author={Dao, Tri and Gu, Albert and Ratner, Alexander J and Smith, Virginia and De Sa, Christopher and R{\'e}, Christopher},
  journal={Proceedings of machine learning research},
  volume={97},
  pages={1528},
  year={2019},
  publisher={NIH Public Access}
}

@misc{chen2019grouptheoretic,
    title={A Group-Theoretic Framework for Data Augmentation},
    author={Shuxiao Chen and Edgar Dobriban and Jane H Lee},
    year={2019},
    eprint={1907.10905},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{xu2014scale,
  title={Scale-invariant convolutional neural networks},
  author={Xu, Yichong and Xiao, Tianjun and Zhang, Jiaxing and Yang, Kuiyuan and Zhang, Zheng},
  journal={arXiv preprint arXiv:1411.6369},
  year={2014}
}

@misc{kanazawa2014locally,
    title={Locally Scale-Invariant Convolutional Neural Networks},
    author={Angjoo Kanazawa and Abhishek Sharma and David Jacobs},
    year={2014},
    eprint={1412.5104},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{abts2020think,
  title={Think fast: a tensor streaming processor (TSP) for accelerating deep learning workloads},
  author={Abts, Dennis and Ross, Jonathan and Sparling, Jonathan and Wong-VanHaren, Mark and Baker, Max and Hawkins, Tom and Bell, Andrew and Thompson, John and Kahsai, Temesghen and Kimmell, Garrin and others},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  pages={145--158},
  year={2020},
  organization={IEEE}
}

@article{chen2014diannao,
  title={Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning},
  author={Chen, Tianshi and Du, Zidong and Sun, Ninghui and Wang, Jia and Wu, Chengyong and Chen, Yunji and Temam, Olivier},
  journal={ACM SIGARCH Computer Architecture News},
  volume={42},
  number={1},
  pages={269--284},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@article{chen2016diannao,
  title={DianNao family: energy-efficient hardware accelerators for machine learning},
  author={Chen, Yunji and Chen, Tianshi and Xu, Zhiwei and Sun, Ninghui and Temam, Olivier},
  journal={Communications of the ACM},
  volume={59},
  number={11},
  pages={105--112},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{jouppi2017datacenter,
  title={In-datacenter performance analysis of a tensor processing unit},
  author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
  booktitle={Proceedings of the 44th Annual International Symposium on Computer Architecture},
  pages={1--12},
  year={2017}
}

@inproceedings {222605,
author = {Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I. Jordan and Ion Stoica},
title = {Ray: A Distributed Framework for Emerging {AI} Applications},
booktitle = {13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
year = {2018},
isbn = {978-1-931971-47-8},
address = {Carlsbad, CA},
pages = {561--577},
url = {https://www.usenix.org/conference/osdi18/presentation/moritz},
publisher = {{USENIX} Association},
month = oct,
}


@inproceedings{barham2019machine,
  title={Machine Learning Systems are Stuck in a Rut},
  author={Barham, Paul and Isard, Michael},
  booktitle={Proceedings of the Workshop on Hot Topics in Operating Systems},
  pages={177--183},
  year={2019},
  organization={ACM}
}

@InProceedings{pmlr-v97-ying19a,
  title = 	 {{NAS}-Bench-101: Towards Reproducible Neural Architecture Search},
  author = 	 {Ying, Chris and Klein, Aaron and Christiansen, Eric and Real, Esteban and Murphy, Kevin and Hutter, Frank},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7105--7114},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/ying19a/ying19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/ying19a.html},
  abstract = 	 {Recent advances in neural architecture search (NAS) demand tremendous computational resources, which makes it difficult to reproduce experiments and imposes a barrier-to-entry to researchers without access to large-scale computation. We aim to ameliorate these problems by introducing NAS-Bench-101, the first public architecture dataset for NAS research. To build NAS-Bench-101, we carefully constructed a compact, yet expressive, search space, exploiting graph isomorphisms to identify 423k unique convolutional architectures. We trained and evaluated all of these architectures multiple times on CIFAR-10 and compiled the results into a large dataset of over 5 million trained models. This allows researchers to evaluate the quality of a diverse range of models in milliseconds by querying the pre-computed dataset. We demonstrate its utility by analyzing the dataset as a whole and by benchmarking a range of architecture optimization algorithms.}
}


@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Mon, 13 Aug 2018 16:46:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{NIPS2018_7599,
title = {Learning to Optimize Tensor Programs},
author = {Chen, Tianqi and Zheng, Lianmin and Yan, Eddie and Jiang, Ziheng and Moreau, Thierry and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {3389--3400},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7599-learning-to-optimize-tensor-programs.pdf}
}

@inproceedings{Kim:2019:CGH:3314872.3314885,
 author = {Kim, Jinsung and Sukumaran-Rajam, Aravind and Thumma, Vineeth and Krishnamoorthy, Sriram and Panyala, Ajay and Pouchet, Louis-No\"{e}l and Rountev, Atanas and Sadayappan, P.},
 title = {A Code Generator for High-performance Tensor Contractions on GPUs},
 booktitle = {Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization},
 series = {CGO 2019},
 year = {2019},
 isbn = {978-1-7281-1436-1},
 location = {Washington, DC, USA},
 pages = {85--95},
 numpages = {11},
 url = {http://dl.acm.org/citation.cfm?id=3314872.3314885},
 acmid = {3314885},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Code Generation, GPU Computing, Tensor Contractions},
} 

@article{Li:2018:DPI,
    title = {Differentiable programming for image processing and deep learning in {Halide}},
    author = {Li, Tzu-Mao and Gharbi, Micha{\"e}l and Adams, Andrew and Durand, Fr{\'e}do and Ragan-Kelley, Jonathan},
    journal = {ACM Trans. Graph. (Proc. SIGGRAPH)},
    volume = {37},
    number = {4},
    pages = {139:1--139:13},
    year = {2018}
}

@inproceedings{metaflow_sysml19,
    author = {Jia, Zhihao and Zaharia, Matei and Aiken, Alex},
    title = {{Optimizing DNN Computation with Relaxed Graph Substitutions}},
    booktitle = {2nd Conference on Systems and Machine Learning (SysML)},
    year = {2019},
    month = {Apr},
    location = {Palo Alto, CA, USA},
}

@inproceedings{soap_sysml19,
    author = {Jia, Zhihao and Thomas, James and Warszawski, Todd and Gao, Mingyu and Zaharia, Matei and Aiken, Alex},
    title = {{Beyond data and model parallelism for deep neural networks}},
    booktitle = {2nd Conference on Systems and Machine Learning (SysML)},
    year = {2019},
    month = {Apr},
    location = {Palo Alto, CA, USA},
}

@article{moreau2019hardware,
  title={A Hardware-Software Blueprint for Flexible Deep Learning Specialization},
  author={Moreau, Thierry and Chen, Tianqi and Vega, Luis and Roesch, Jared and Zheng, Lianmin and Yan, Eddie and Fromm, Josh and Jiang, Ziheng and Ceze, Luis and Guestrin, Carlos and others},
  journal={IEEE Micro},
  year={2019},
  publisher={IEEE}
}

@ARTICLE{2018arXiv181200332C,
       author = {{Cai}, Han and {Zhu}, Ligeng and {Han}, Song},
        title = "{ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = "2018",
        month = "Dec",
          eid = {arXiv:1812.00332},
        pages = {arXiv:1812.00332},
archivePrefix = {arXiv},
       eprint = {1812.00332},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181200332C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{tan2019mnasnet,
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2820--2828},
  year={2019}
}

@article{ragan2017halide,
  title={Halide: decoupling algorithms from schedules for high-performance image processing},
  author={Ragan-Kelley, Jonathan and Adams, Andrew and Sharlet, Dillon and Barnes, Connelly and Paris, Sylvain and Levoy, Marc and Amarasinghe, Saman and Durand, Fr{\'e}do},
  journal={Communications of the ACM},
  volume={61},
  number={1},
  pages={106--115},
  year={2017},
  publisher={ACM}
}

@inproceedings{zoph2018learning,
  title={Learning transferable architectures for scalable image recognition},
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8697--8710},
  year={2018}
}


@inproceedings{mirhoseini2017device,
  title={Device placement optimization with reinforcement learning},
  author={Mirhoseini, Azalia and Pham, Hieu and Le, Quoc V and Steiner, Benoit and Larsen, Rasmus and Zhou, Yuefeng and Kumar, Naveen and Norouzi, Mohammad and Bengio, Samy and Dean, Jeff},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2430--2439},
  year={2017},
  organization={JMLR. org}
}


@article{DBLP:journals/corr/abs-1905-12799,
  author    = {Byung Hoon Ahn and
               Prannoy Pilligundla and
               Hadi Esmaeilzadeh},
  title     = {Reinforcement Learning and Adaptive Sampling for Optimized {DNN} Compilation},
  journal   = {CoRR},
  volume    = {abs/1905.12799},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12799},
  archivePrefix = {arXiv},
  eprint    = {1905.12799},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-12799},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{anderson2018optimal,
  title={Optimal DNN primitive selection with partitioned boolean quadratic programming},
  author={Anderson, Andrew and Gregg, David},
  booktitle={Proceedings of the 2018 International Symposium on Code Generation and Optimization},
  pages={340--351},
  year={2018},
  organization={ACM}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016},
  organization={ACM}
}

@article{tan2019mixnet,
  title={MixNet: Mixed Depthwise Convolutional Kernels},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1907.09595},
  year={2019}
}

@article{Burns:2016:BOK:2930840.2890784,
 author = {Burns, Brendan and Grant, Brian and Oppenheimer, David and Brewer, Eric and Wilkes, John},
 title = {Borg, Omega, and Kubernetes},
 journal = {Commun. ACM},
 issue_date = {May 2016},
 volume = {59},
 number = {5},
 month = apr,
 year = {2016},
 issn = {0001-0782},
 pages = {50--57},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2890784},
 doi = {10.1145/2890784},
 acmid = {2890784},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Hindman:Mesos,
 author = {Hindman, Benjamin and Konwinski, Andy and Zaharia, Matei and Ghodsi, Ali and Joseph, Anthony D. and Katz, Randy and Shenker, Scott and Stoica, Ion},
 title = {Mesos: A Platform for Fine-grained Resource Sharing in the Data Center},
 booktitle = {Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation},
 series = {NSDI'11},
 year = {2011},
 location = {Boston, MA},
 pages = {295--308},
 numpages = {14},
 url = {http://dl.acm.org/citation.cfm?id=1972457.1972488},
 acmid = {1972488},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
}

@article{liu2018darts,
  title={Darts: Differentiable architecture search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={arXiv preprint arXiv:1806.09055},
  year={2018}
}

@inproceedings{golovin2017google,
  title={Google vizier: A service for black-box optimization},
  author={Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1487--1495},
  year={2017},
  organization={ACM}
}

@inproceedings{fromm2018heterogeneous,
  title={Heterogeneous bitwidth binarization in convolutional neural networks},
  author={Fromm, Joshua and Patel, Shwetak and Philipose, Matthai},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4006--4015},
  year={2018}
}

@article{mao2019park,
  title={Park: An Open Platform for Learning Augmented Computer Systems},
  author={Mao, Hongzi and Negi, Parimarjan and Narayan, Akshay and Wang, Hanrui and Yang, Jiacheng and Wang, Haonan and Marcus, Ryan and Addanki, Ravichandra and Khani, Mehrdad and He, Songtao and Cangialosi, Frank and Bojja Venkatakrishnan, Shaileshh and Weng, Wei-Hung and Han, Song and Kraska, Tim, and Alizadeh, Mohammad},
  year={2019}
}

@article{xing2019dnnvm,
  title={DNNVM: End-to-end compiler leveraging heterogeneous optimizations on FPGA-based cnn accelerators},
  author={Xing, Yu and Liang, Shuang and Sui, Lingzhi and Jia, Xijie and Qiu, Jiantao and Liu, Xin and Wang, Yushun and Shan, Yi and Wang, Yu},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year={2019},
  publisher={IEEE}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{blott2018finn,
  title={FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks},
  author={Blott, Michaela and Preusser, Thomas B and Fraser, Nicholas J and Gambardella, Giulio and O’brien, Kenneth and Umuroglu, Yaman and Leeser, Miriam and Vissers, Kees},
  journal={ACM Transactions on Reconfigurable Technology and Systems (TRETS)},
  volume={11},
  number={3},
  pages={16},
  year={2018},
  publisher={ACM}
}

@inproceedings{koeplinger2018spatial,
  title={Spatial: A language and compiler for application accelerators},
  author={Koeplinger, David and Feldman, Matthew and Prabhakar, Raghu and Zhang, Yaqi and Hadjis, Stefan and Fiszel, Ruben and Zhao, Tian and Nardi, Luigi and Pedram, Ardavan and Kozyrakis, Christos and others},
  booktitle={ACM Sigplan Notices},
  volume={53},
  number={4},
  pages={296--311},
  year={2018},
  organization={ACM}
}

@article{Koeplinger:2016:AGE:3007787.3001150,
 author = {Koeplinger, David and Delimitrou, Christina and Prabhakar, Raghu and Kozyrakis, Christos and Zhang, Yaqi and Olukotun, Kunle},
 title = {Automatic Generation of Efficient Accelerators for Reconfigurable Hardware},
 journal = {SIGARCH Comput. Archit. News},
 issue_date = {June 2016},
 volume = {44},
 number = {3},
 month = jun,
 year = {2016},
 issn = {0163-5964},
 pages = {115--127},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3007787.3001150},
 doi = {10.1145/3007787.3001150},
 acmid = {3001150},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Tai2015ImprovedSR,
  title={Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks},
  author={Kai Sheng Tai and Richard Socher and Christopher D. Manning},
  booktitle={ACL},
  year={2015}
}

@article{Adams2019LearningTO,
  title={Learning to optimize halide with tree search and random programs},
  author={Andrew Adams and Karima Ma and Luke S. Anderson and Riyadh Baghdadi and Tzu-Mao Li and Micha{\"e}l Gharbi and Benoit Steiner and Steven Johnson and Kayvon Fatahalian and Fr{\'e}do Durand and Jonathan Ragan-Kelley},
  journal={ACM Trans. Graph.},
  year={2019},
  volume={38},
  pages={121:1-121:12}
}

@article{mullapudi2016automatically,
  title={Automatically scheduling halide image processing pipelines},
  author={Mullapudi, Ravi Teja and Adams, Andrew and Sharlet, Dillon and Ragan-Kelley, Jonathan and Fatahalian, Kayvon},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={83},
  year={2016},
  publisher={ACM}
}

@InProceedings{Yang_2018_ECCV,
author = {Yang, Tien-Ju and Howard, Andrew and Chen, Bo and Zhang, Xiao and Go, Alec and Sandler, Mark and Sze, Vivienne and Adam, Hartwig},
title = {NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
} 

@INPROCEEDINGS{8009208,
author={B. {Reagen} and J. M. {Hernández-Lobato} and R. {Adolf} and M. {Gelbart} and P. {Whatmough} and G. {Wei} and D. {Brooks}},
booktitle={2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)},
title={A case for efficient accelerator design space exploration via Bayesian optimization},
year={2017},
volume={},
number={},
pages={1-6},
keywords={Bayes methods;learning (artificial intelligence);neural nets;optimisation;accelerator design space exploration;Bayesian optimization;machine learning;deep neural network hardware accelerators;DNN accelerators;optimization space;Acceleration;Energy efficiency;Program processors;Bayes methods;Annealing;Prediction algorithms;Microarchitecture},
doi={10.1109/ISLPED.2017.8009208},
ISSN={},
month={July},}

@misc{sosnovik2019scaleequivariant,
    title={Scale-Equivariant Steerable Networks},
    author={Ivan Sosnovik and Michał Szmaja and Arnold Smeulders},
    year={2019},
    eprint={1910.11093},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
